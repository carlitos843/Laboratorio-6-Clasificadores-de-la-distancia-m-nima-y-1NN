from sklearn.datasets import load_iris, load_wine, load_digits
from sklearn.model_selection import train_test_split, StratifiedKFold, LeaveOneOut
from sklearn.metrics import accuracy_score, confusion_matrix
import numpy as np
import pandas as pd
from scipy.spatial.distance import cdist

# Cargar los datasets
datasets = {
    "Iris": load_iris(),
    "Wine": load_wine(),
    "Digits": load_digits()
}

# Convertir cada dataset a un DataFrame para facilitar el manejo
dataframes = {name: pd.DataFrame(data.data, columns=data.feature_names) for name, data in datasets.items()}
for name, data in datasets.items():
    dataframes[name]['target'] = data.target

# Función para calcular los centroides de cada clase
def calcular_centroides(X_train, y_train):
    clases = np.unique(y_train)
    centroides = {clase: X_train[y_train == clase].mean(axis=0) for clase in clases}
    return centroides

# Clasificador de la Distancia Mínima
def clasificador_distancia_minima(X_test, centroides):
    centroides_array = np.array(list(centroides.values()))
    clases = np.array(list(centroides.keys()))
    distancias = cdist(X_test, centroides_array, metric='euclidean')
    indices_min_dist = distancias.argmin(axis=1)
    return clases[indices_min_dist]

# Método de validación Hold-Out 70/30 Estratificado
def hold_out_7030(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)
    centroides = calcular_centroides(X_train, y_train)
    y_pred = clasificador_distancia_minima(X_test, centroides)
    accuracy = accuracy_score(y_test, y_pred)
    matriz_confusion = confusion_matrix(y_test, y_pred)
    return accuracy, matriz_confusion

# Método de validación 10-Fold Cross-Validation Estratificado
def cross_validation_10_fold(X, y):
    skf = StratifiedKFold(n_splits=10)
    accuracies = []
    matrices_confusion = []

    for train_index, test_index in skf.split(X, y):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]
        centroides = calcular_centroides(X_train, y_train)
        y_pred = clasificador_distancia_minima(X_test, centroides)
        accuracies.append(accuracy_score(y_test, y_pred))
        matrices_confusion.append(confusion_matrix(y_test, y_pred))

    promedio_accuracy = np.mean(accuracies)
    return promedio_accuracy, matrices_confusion

# Método de validación Leave-One-Out
def leave_one_out_validation(X, y):
    loo = LeaveOneOut()
    y_true, y_pred = [], []

    for train_index, test_index in loo.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]
        centroides = calcular_centroides(X_train, y_train)
        pred = clasificador_distancia_minima(X_test, centroides)
        y_true.append(y_test[0])
        y_pred.append(pred[0])

    accuracy = accuracy_score(y_true, y_pred)
    matriz_confusion = confusion_matrix(y_true, y_pred)
    return accuracy, matriz_confusion

# Ejecutar los métodos de validación en el dataset Iris como ejemplo
X = datasets["Iris"].data
y = datasets["Iris"].target

# Hold-Out 70/30 Estratificado
accuracy_hold_out, matriz_confusion_hold_out = hold_out_7030(X, y)
print("Hold-Out 70/30 Estratificado")
print("Accuracy:", accuracy_hold_out)
print("Matriz de Confusión:\n", matriz_confusion_hold_out)

# 10-Fold Cross-Validation Estratificado
accuracy_10fold, matrices_confusion_10fold = cross_validation_10_fold(X, y)
print("\n10-Fold Cross-Validation Estratificado")
print("Accuracy:", accuracy_10fold)
print("Matriz de Confusión (promedio):\n", np.mean(matrices_confusion_10fold, axis=0))

# Leave-One-Out
accuracy_loo, matriz_confusion_loo = leave_one_out_validation(X, y)
print("\nLeave-One-Out")
print("Accuracy:", accuracy_loo)
print("Matriz de Confusión:\n", matriz_confusion_loo)
